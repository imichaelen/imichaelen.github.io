---
title: "Daily Issue (JST): 2026-02-21"
---

# Daily Issue (JST): 2026-02-21

## What's New Today

**AI Efficiency Advances and Materials Discovery Drive Today's Research**

Today's research spans efficient AI model design and novel materials simulation. New methods for pruning diffusion models and compressing time series models promise faster inference. In materials science, high-throughput screening and first-principles simulations accelerate the discovery of polymer electrolytes and elucidate surface adsorption dynamics.

**Highlights**
- Sink-aware pruning challenges assumptions for efficient diffusion language models.
- High-throughput molecular dynamics screens 1.7M polymers for battery electrolytes.
- First-principles method constructs Newns-Anderson Hamiltonians for surface adsorption.
- Small hybrid models match large transformers for zero-shot time series forecasting.
- Margin-aware reward modeling (MARS) targets ambiguous data for better alignment.
- Unified latent framework (UL) combines diffusion prior and decoder for efficient generation.

**Themes**
- AI: Efficient Model Architectures & Training
- AI: Alignment & Reward Modeling
- AI: Time Series & Multimodal Learning
- Materials: High-Throughput Discovery
- Materials: First-Principles Simulation
- Physics: Surface & Interface Science

**Keywords**
- model pruning
- diffusion models
- high-throughput screening
- polymer electrolytes
- first-principles
- Newns-Anderson Hamiltonian
- time series foundation models
- reward modeling
- latent representation
- surface adsorption
- molecular dynamics
- zero-shot forecasting

**Total new papers:** 237

## Featured Papers

### [Sink-Aware Pruning for Diffusion Language Models](https://arxiv.org/abs/2602.17664v1)
**Authors:** Aidar Myrzakhan, Tianyi Li, Bowei Guo, Shengkun Tang, Zhiqiang Shen
**Published:** 2026-02-19
**Summary:** Sink-Aware Pruning identifies and prunes unstable attention sink tokens in Diffusion Language Models, improving efficiency without retraining.

**What's new**
- Shows attention sinks in DLMs are transient with high variance across timesteps, unlike stable sinks in AR LLMs.
- Proposes Sink-Aware Pruning to automatically prune unstable sinks in DLMs, unlike prior work preserving sinks for AR LLMs.
- Achieves better quality-efficiency trade-off without retraining, outperforming prior pruning baselines under matched compute.

### [MARS: Margin-Aware Reward-Modeling with Self-Refinement](https://arxiv.org/abs/2602.17658v1)
**Authors:** Payel Bhattacharjee, Osvaldo Simeone, Ravi Tandon
**Published:** 2026-02-19
**Summary:** MARS is a reward modeling framework that adaptively augments ambiguous preference data to improve alignment training efficiency and robustness.

**What's new**
- Proposes margin-aware augmentation targeting low-margin, uncertain preference pairs for reward models
- Introduces iterative self-refinement via hard-sample augmentation to refine the training distribution
- Provides theoretical guarantees on increased loss curvature and improved conditioning
- Demonstrates empirical gains over uniform augmentation for robust reward modeling

### [Reverso: Efficient Time Series Foundation Models for Zero-shot Forecasting](https://arxiv.org/abs/2602.17634v1)
**Authors:** Xinghong Fu, Yanhong Li, Georgios Papaioannou, Yoon Kim
**Published:** 2026-02-19
**Summary:** Reverso introduces small, efficient hybrid models using long convolutions and linear RNNs that match large transformer performance for zero-shot time series forecasting while being over 100x smaller.

**What's new**
- Proposes small hybrid models (long convolution + linear RNN) that match large transformer performance for zero-shot forecasting.
- Achieves over 100x parameter reduction compared to existing time series foundation models.
- Introduces data augmentation and inference strategies to further boost model performance.
- Pushes the performance-efficiency Pareto frontier for practical, deployable time series models.

### [First-principles Newns-Anderson Hamiltonian Construction for Chemisorbed Hydrogen at Metal Surfaces](https://arxiv.org/abs/2602.17635v1)
**Authors:** Nils Hertl, Zsuszanna Koczor-Benda, Reinhard J. Maurer
**Published:** 2026-02-19
**Summary:** A first-principles method constructs Newns-Anderson Hamiltonians for hydrogen on metals, validating couplings and assessing wideband limit approximations.

**What's new**
- Uses projection operator diabatisation on DFT Hamiltonians for first-principles Newns-Anderson model construction.
- Validates method for H on Al, Cu, Pt(111) via PDOS, tunneling, and vibrational lifetimes against reference calculations.
- Shows wideband limit approximation holds for H/Al(111) but is limited for H/Cu(111) and H/Pt(111).

### [Asymptotic Smoothing of the Lipschitz Loss Landscape in Overparameterized One-Hidden-Layer ReLU Networks](https://arxiv.org/abs/2602.17596v1)
**Authors:** Saveliy Baturin
**Published:** 2026-02-19
**Summary:** Overparameterized ReLU networks have flatter loss landscapes where local minima become nearly global as width increases, both theoretically and empirically.

**What's new**
- Proves any two models at same loss can be connected with arbitrarily small loss increase for convex Lipschitz losses
- Shows energy gap between local and global minima vanishes asymptotically as network width grows
- Empirically measures smaller energy gaps in wider networks using Dynamic String Sampling
- Permutation test yields p=0, indicating clear reduction in loss landscape barriers

### [AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games](https://arxiv.org/abs/2602.17594v1)
**Authors:** Lance Ying, Ryan Truong, Prafull Sharma, Kaiya Ivy Zhao, Nathan Cloos, Kelsey R. Allen, Thomas L. Griffiths, Katherine M. Collins, José Hernández-Orallo, Phillip Isola, Samuel J. Gershman, Joshua B. Tenenbaum
**Published:** 2026-02-19
**Summary:** AI GameStore is a scalable platform that evaluates machine general intelligence by testing AI systems on a vast, LLM-generated library of human digital games.

**What's new**
- Proposes evaluating AI on the 'Multiverse of Human Games'—all conceivable games designed for humans—as a test for general intelligence.
- Introduces the AI GameStore platform, which uses LLMs and humans-in-the-loop to automatically source and synthesize new, representative human games.
- Generated 100 games from top App Store/Steam charts as a proof of concept, finding frontier VLMs achieve <10% of human average score on most.
- Highlights that models particularly struggle with games requiring world-model learning, memory, and planning capabilities.
- Outlines a path for using this open-ended, scalable platform to measure and drive progress toward human-like machine intelligence.

### [Modeling Distinct Human Interaction in Web Agents](https://arxiv.org/abs/2602.17588v1)
**Authors:** Faria Huq, Zora Zhiruo Wang, Zhanqiu Guo, Venu Arvind Arangarajan, Tianyue Ou, Frank Xu, Shuyan Zhou, Graham Neubig, Jeffrey P. Bigham
**Published:** 2026-02-19
**Summary:** This paper introduces a framework to model distinct patterns of human intervention in web agents, improving prediction accuracy and user-rated usefulness.

**What's new**
- Introduces CowCorpus, a dataset of 400 real-user web navigation trajectories with over 4,200 human-agent actions.
- Identifies four distinct patterns of user interaction: hands-off supervision, hands-on oversight, collaborative task-solving, and full takeover.
- Trains LMs to anticipate user interventions, achieving a 61.4-63.4% accuracy improvement over base models.
- Deploys intervention-aware agents in a user study, resulting in a 26.5% increase in user-rated usefulness.

### [Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space](https://arxiv.org/abs/2602.17586v1)
**Authors:** Antonio Guillen-Perez
**Published:** 2026-02-19
**Summary:** Deep-Flow uses flow matching on a spectral manifold for stable, unsupervised anomaly detection in autonomous driving, distinguishing kinematic danger from semantic non-compliance.

**What's new**
- Uses OT-CFM on a PCA-constrained spectral manifold for stable, deterministic log-likelihood estimation of driving behavior.
- Introduces an Early Fusion Transformer with lane-aware goal conditioning and skip-connections to resolve multi-modal intent at junctions.
- Employs a kinematic complexity weighting scheme prioritizing high-energy maneuvers during training for rare event detection.
- Identifies a predictability gap by detecting semantic non-compliance (e.g., lane violations) overlooked by traditional safety filters.

### [The influence of Y content on grain structure evolution in Mg-Y alloys](https://arxiv.org/abs/2602.17580v1)
**Authors:** Qianying Shi, Vaidehi Menon, Liang Qi, John Allison
**Published:** 2026-02-19
**Summary:** Yttrium addition retards grain evolution in Mg alloys via solute drag at grain boundaries, enabling design of thermally stable microstructures.

**What's new**
- Y addition significantly retards static recrystallization and grain growth via solute drag at grain boundaries.
- Static recrystallization proceeds via a two-stage behavior with distinct JMAK exponents, indicating heterogeneous nucleation.
- Abnormal grain growth (AGG) behavior was observed in Mg-Y alloys.
- Relative solute drag effects of alloying elements were assessed from thermodynamic and kinetic perspectives.

### [Simultaneous Blackwell Approachability and Applications to Multiclass Omniprediction](https://arxiv.org/abs/2602.17577v1)
**Authors:** Lunjia Hu, Kevin Tian, Chutong Yang
**Published:** 2026-02-19
**Summary:** Extends omniprediction to multiclass settings with infinite comparator families via simultaneous Blackwell approachability, achieving sample complexity/regret scaling with ε^-(k+1) for k classes.

**What's new**
- Introduces multiclass omniprediction with possibly infinite comparator families
- Extends binary omniprediction algorithm to multiclass setting with ε^-(k+1) scaling
- Develops simultaneous Blackwell approachability framework for coupled actions
- Provides applications to statistical and online learning settings
- Enables suboptimality bounds across multiple loss families simultaneously

### [ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment](https://arxiv.org/abs/2602.17560v1)
**Authors:** Hongjue Zhao, Haosen Sun, Jiangtao Kong, Xiaochang Li, Qineng Wang, Liwei Jiang, Qi Zhu, Tarek Abdelzaher, Yejin Choi, Manling Li, Huajie Shao
**Published:** 2026-02-19
**Summary:** ODESteer is a new activation steering framework for LLM alignment that uses ordinary differential equations and barrier functions for multi-step, adaptive control of internal model activations.

**What's new**
- Proposes a unified ODE-based theoretical framework, interpreting activation addition as a first-order ODE approximation.
- Links steering direction design to constructing barrier functions from control theory for principled guidance.
- Introduces multi-step, adaptive steering instead of one-step methods to capture complex activation patterns.
- Defines the barrier function as the log-density ratio between positive and negative activations to identify steering directions.
- Shows empirical gains, including a 5.7% improvement on TruthfulQA over prior activation steering methods.

### [A Theoretical Framework for Modular Learning of Robust Generative Models](https://arxiv.org/abs/2602.17554v1)
**Authors:** Corinna Cortes, Mehryar Mohri, Yutao Zhong
**Published:** 2026-02-19
**Summary:** A theoretical framework for robustly combining small, domain-specific generative models via an optimized gating mechanism to match or exceed monolithic training performance.

**What's new**
- Proves existence of a robust gating function minimizing divergence to worst-case data mixtures via fixed-point theorem
- Shows modularity acts as regularizer with generalization bounds scaling with gate complexity
- Proves modular approach can outperform models retrained on aggregate data via Jensen-Shannon Divergence gap
- Introduces scalable Stochastic Primal-Dual algorithm and Structural Distillation for efficient inference

### [MASPO: Unifying Gradient Utilization, Probability Mass, and Signal Reliability for Robust and Sample-Efficient LLM Reasoning](https://arxiv.org/abs/2602.17550v1)
**Authors:** Xiaoliang Fu, Jiaye Lin, Yangyi Fang, Binbin Zheng, Chaowen Hu, Zekai Shao, Cong Qin, Lu Pan, Ke Zeng, Xunliang Cai
**Published:** 2026-02-19
**Summary:** MASPO is a new reinforcement learning method for LLMs that improves sample efficiency and robustness by better aligning gradient updates with token distributions and reward signal reliability.

**What's new**
- Replaces hard gradient clipping with a soft Gaussian gating mechanism for more efficient gradient utilization.
- Introduces a mass-adaptive limiter that adjusts constraints based on token probability distribution.
- Implements an asymmetric risk controller to handle positive and negative reward signals differently based on confidence.
- Unifies gradient utility, probability mass sensitivity, and signal reliability in a single framework.
- Demonstrates superior performance over existing RLVR methods like GRPO in extensive evaluations.

### [Learning to Stay Safe: Adaptive Regularization Against Safety Degradation during Fine-Tuning](https://arxiv.org/abs/2602.17546v1)
**Authors:** Jyotin Goel, Souvik Maji, Pratik Mazumder
**Published:** 2026-02-19
**Summary:** A fine-tuning framework that adapts regularization based on estimated safety risk to prevent safety degradation while preserving utility.

**What's new**
- Introduces adaptive regularization that constrains high-risk updates to stay near a safe reference policy.
- Proposes two safety risk estimators: a judge-based Safety Critic and an activation-based predictor.
- Shows harmful intent is predictable from pre-generation model activations.
- Empirically lowers attack success rates across models and attacks without inference cost.
- Preserves downstream task performance, avoiding the typical safety-utility trade-off.

### [Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability](https://arxiv.org/abs/2602.17544v1)
**Authors:** Shashank Aggarwal, Ram Vikas Mishra, Amit Awekar
**Published:** 2026-02-19
**Summary:** Proposes reusability and verifiability as new metrics to evaluate Chain-of-Thought reasoning quality, showing they don't correlate with standard accuracy.

**What's new**
- Introduces two novel metrics: reusability (ease of reusing CoT) and verifiability (frequency of matching answer using CoT).
- Uses a Thinker-Executor framework to decouple CoT generation from execution for evaluation.
- Finds no correlation between new metrics and standard accuracy, revealing a blind spot in current leaderboards.
- Shows specialized reasoning models don't consistently produce more reusable/verifiable CoTs than general LLMs.

### [Using LLMs for Knowledge Component-level Correctness Labeling in Open-ended Coding Problems](https://arxiv.org/abs/2602.17542v1)
**Authors:** Zhangqi Duan, Arnav Kankaria, Dhruv Kartik, Andrew Lan
**Published:** 2026-02-19
**Summary:** An automated framework using LLMs to label fine-grained knowledge component correctness in student code, improving learning curve analysis over problem-level baselines.

**What's new**
- Uses LLMs to directly label KC correctness from student-written code, avoiding simple problem-level propagation.
- Introduces a temporal context-aware Code-KC mapping to better align KCs with individual student solutions.
- Evaluates labels via learning curve fit and predictive models, showing results more consistent with cognitive theory.
- Human evaluation shows substantial agreement between LLM-generated and expert annotations.

### [IRIS: Learning-Driven Task-Specific Cinema Robot Arm for Visuomotor Motion Control](https://arxiv.org/abs/2602.17537v1)
**Authors:** Qilong Cheng, Matthew Mackay, Ali Bereyhi
**Published:** 2026-02-19
**Summary:** IRIS is a low-cost, 3D-printed 6-DOF robot arm that uses imitation learning to autonomously execute smooth, object-aware cinematic camera motions from human demonstrations.

**What's new**
- Integrates a fully 3D-printed, low-cost (<$1k) hardware design with 1 mm repeatability for cinematic use.
- Uses a goal-conditioned visuomotor imitation learning framework (ACT) to learn from human demonstrations.
- Eliminates explicit geometric programming by learning object-aware and perceptually smooth trajectories directly.
- Demonstrates reliable autonomous execution and generalization across diverse real-world cinematic motions.

### [Toward a Fully Autonomous, AI-Native Particle Accelerator](https://arxiv.org/abs/2602.17536v1)
**Authors:** Chris Tennant
**Published:** 2026-02-19
**Summary:** A vision for particle accelerators designed from the ground up by AI to enable fully autonomous, high-performance operation.

**What's new**
- Proposes AI co-design from inception to jointly optimize accelerator lattice, diagnostics, and science applications
- Outlines nine research thrusts including agentic control, adaptive learning, and AI-native safety frameworks
- Shifts from retrofitting AI to building AI-native platforms for autonomous operation and reliability

### [Position: Evaluation of ECG Representations Must Be Fixed](https://arxiv.org/abs/2602.17531v1)
**Authors:** Zachary Berger, Daniel Prakah-Asante, John Guttag, Collin M. Stultz
**Published:** 2026-02-19
**Summary:** This paper argues that ECG representation learning benchmarks are too narrow and proposes expanded clinical evaluations and better practices, showing random encoders can match state-of-the-art pre-training.

**What's new**
- Criticizes current ECG benchmarks for focusing only on arrhythmia, urging inclusion of structural heart disease and patient forecasting.
- Shows applying proper multi-label, imbalanced evaluation practices changes which representations are considered best.
- Finds a randomly initialized encoder with linear evaluation often matches state-of-the-art pre-training performance.
- Proposes using a random encoder as a necessary baseline model for future ECG representation studies.

### [Interpretable Machine Learning of Nanoparticle Stability through Topological Layer Embeddings](https://arxiv.org/abs/2602.17528v1)
**Authors:** Felipe Hawthorne, Leandro Seixas, James M. Almeida, Cristiano F. Woellner, Raphael M. Tromer
**Published:** 2026-02-19
**Summary:** A machine learning framework uses topological layer embeddings to efficiently and interpretably predict nanoparticle stability from limited DFT data.

**What's new**
- Introduces a fragmented, layer-resolved descriptor that decomposes nanoparticles into surface, intermediate, and core regions.
- Achieves high data efficiency, accurately identifying stable configurations with only a few hundred DFT calculations.
- Employs a ranking-based learning strategy with gradient-boosted trees for robust performance on small datasets.
- Provides physical interpretability via layer-weighting and SHAP analysis, revealing factors like surface segregation.
- Establishes a pathway for active learning-driven exploration of complex nanoparticle configurational spaces.

### [Variational inference via radial transport](https://arxiv.org/abs/2602.17525v1)
**Authors:** Luca Ghafourpour, Sinho Chewi, Alessio Figalli, Aram-Alexandre Pooladian
**Published:** 2026-02-19
**Summary:** A cheap add-on algorithm for variational inference that improves approximation by optimizing radial profiles of distributions, with theoretical guarantees.

**What's new**
- Optimizes radial profiles to capture correct distribution shapes beyond simple Gaussians
- Acts as an effective add-on to existing VI schemes like mean-field VI and Laplace
- Provides theoretical convergence guarantees using Wasserstein space optimization
- Leverages new regularity properties of radial transport maps for analysis

### [Bridging the Domain Divide: Supervised vs. Zero-Shot Clinical Section Segmentation from MIMIC-III to Obstetrics](https://arxiv.org/abs/2602.17513v1)
**Authors:** Baris Karacan, Barbara Di Eugenio, Patrick Thornton
**Published:** 2026-02-19
**Summary:** This paper compares supervised and zero-shot models for segmenting clinical notes, showing supervised models struggle out-of-domain while zero-shot models adapt well if hallucinations are corrected.

**What's new**
- Introduces a new de-identified, section-labeled dataset of obstetrics notes to expand beyond MIMIC-III.
- Systematically evaluates transformer-based supervised models on both in-domain (MIMIC-III) and out-of-domain (obstetrics) data.
- Conducts the first head-to-head comparison of supervised models with zero-shot large language models for medical section segmentation.
- Finds supervised models perform well in-domain but drop substantially out-of-domain, while zero-shot models show robust out-of-domain adaptability.
- Highlights that zero-shot segmentation is promising for healthcare NLP beyond well-studied corpora when hallucinations are managed.

### [Pareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems](https://arxiv.org/abs/2602.17508v1)
**Authors:** Pranay Jain, Maximilian Kasper, Göran Köber, Axel Plinge, Dominik Seuß
**Published:** 2026-02-19
**Summary:** A benchmarking framework for optimizing AI models on ARM Cortex processors (M0+, M4, M7) to balance energy efficiency, accuracy, and resource use in embedded systems.

**What's new**
- Automated test bench for systematic evaluation of AI models across ARM Cortex processors using key performance indicators.
- Identifies near-linear correlation between FLOPs and inference time as a reliable metric for computational demand.
- Uses Pareto analysis to balance trade-offs between energy consumption and model accuracy for sustainable AI.
- Finds M7 best for short inference, M4 more energy-efficient for long tasks, and M0+ suitable for simpler models.

### [Proton transfer and hydronium formation in ionized water](https://arxiv.org/abs/2602.17505v1)
**Authors:** Ivo S. Vinklárek, Sebastian Trippel, Michal Belina, Luisa Blum, Hubertus Bromberger, Petr Slavíček, Jochen Küpper
**Published:** 2026-02-19
**Summary:** Time-resolved imaging of ionized water dimers reveals ultrafast proton transfer and hydronium formation, with dynamics shifting from sequential to coupled as energy increases.

**What's new**
- Observed ultrafast proton transfer (~19 fs) at low energy followed by slower H3O+ + OH fragmentation (~360 fs) in water dimer cations.
- At higher energies, proton transfer slows (~60 fs) while fragmentation accelerates (~210 fs), evolving into coupled dynamics above 0.15 eV.
- Identified stabilization of the water dimer cation through a Zundel-like intermediate structure.
- Revealed how energy redistribution in ionized hydrogen-bonded networks steers subsequent aqueous radiation chemistry.

<details><summary>More papers (213)</summary>

**Materials & Physics (cond-mat / comp-ph / chem-ph)**
- [Discovery of Polymer Electrolytes with Bayesian Optimization and High-Throughput Molecular Dynamics simulations](https://arxiv.org/abs/2602.17595v1)
- [Prediction of room-temperature two-dimensional $π$-electron half-metallic ferrimagnets](https://arxiv.org/abs/2602.17489v1)
- [Modeling of Relativistic Plasmas with a Conservative Discontinuous Galerkin Method](https://arxiv.org/abs/2602.17487v1)
- [Multi-Method Li Plating Characterization of a Commercial 26 Ah Li-Ion Pouch-Cell](https://arxiv.org/abs/2602.17455v1)
- [Charge and energy transport in graphene with smooth finite-range disorder](https://arxiv.org/abs/2602.17453v1)
- [Atomic-Scale Surface Imaging of bulk Epitaxial CsPbBr3 Perovskite Single Crystals on Mica using Light Assisted Scanning Tunneling Microscopy at Low-Temperature (80 K)](https://arxiv.org/abs/2602.17388v1)
- [Chiral phonons in sixfold chiral CrSi$_2$: Raman spectroscopy and first-principles calculations](https://arxiv.org/abs/2602.17362v1)
- [Semi-Local Exchange-Correlation Approximations in Density Functional Theory](https://arxiv.org/abs/2602.17333v1)
- [g4chargeit: Geant4-based kinetic Monte Carlo simulations of charging in dielectric materials](https://arxiv.org/abs/2602.17332v1)
- [Unveiling Photoluminescence Signatures of Magneto-Optical Coupling in Layered Hybrid Manganese Chloride Perovskites](https://arxiv.org/abs/2602.17324v1)
- [Effect of oxygen content on optical, structural, and dielectric properties of Al$_x$Ta$_y$O$_z$$ thin films](https://arxiv.org/abs/2602.17302v1)
- [Low-Field Ferroelectric Switching realised by Forced Harmonic Oscillation of Domain Walls](https://arxiv.org/abs/2602.17266v1)
- [On the Concept of Violence: A Comparative Study of Human and AI Judgments](https://arxiv.org/abs/2602.17256v1)
- [Near-single-domain superconducting aluminum films on GaAs(111)A with exceptional crystalline quality for scalable quantum circuits](https://arxiv.org/abs/2602.17249v1)
- [Photocatalytic methanol dehydrogenation promoted synergistically by atomically dispersed Pd and clustered Pd](https://arxiv.org/abs/2602.17228v1)
- [Wide-Surface Furnace for In Situ X-Ray Diffraction of Combinatorial Samples using a High-Throughput Approach](https://arxiv.org/abs/2602.17225v1)
- [Vibrational infrared and Raman spectra of the methanol molecule with equivariant neural-network property surfaces](https://arxiv.org/abs/2602.17219v1)
- [Dielectric Screening in Floquet-Volkov Dressing of Semiconductors](https://arxiv.org/abs/2602.17214v1)
- [Why are there so few non-altermagnetic antiferromagnets?](https://arxiv.org/abs/2602.17181v1)
- [Universal Fine-Grained Symmetry Inference and Enforcement for Rigorous Crystal Structure Prediction](https://arxiv.org/abs/2602.17176v1)
- [Ghost Embedding Bridging Chemistry and One-Body Theories](https://arxiv.org/abs/2602.17164v1)
- [Stochastic tensor contraction for quantum chemistry](https://arxiv.org/abs/2602.17158v1)
- [Rotational Soft Modes and Octahedral Distortion as Design Principles for Ultralow Thermal Conductivity in Halide Materials](https://arxiv.org/abs/2602.17147v1)
- [Elucidating Na$_2$KSb band structure: near-band-gap photoemission spectroscopy and DFT calculations](https://arxiv.org/abs/2602.17105v1)
- [Synergizing Transport-Based Generative Models and Latent Geometry for Stochastic Closure Modeling](https://arxiv.org/abs/2602.17089v1)
- [Order of Magnitude Analysis and Data-Based Physics-Informed Symbolic Regression for Turbulent Pipe Flow](https://arxiv.org/abs/2602.17082v1)
- [Role of atomic vacancies and second-neighbor antiferromagnetic-exchange coupling in a ferromagnetic nanoparticle](https://arxiv.org/abs/2602.17057v1)
- [Finite-size effects and energy alignment in molecular XANES under periodic boundary conditions: A systematic comparison of core-hole treatments](https://arxiv.org/abs/2602.17020v1)

**AI/ML (cs.AI/cs.LG/stat.ML/cs.CL)**
- [CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts](https://arxiv.org/abs/2602.17663v1)
- [What Language is This? Ask Your Tokenizer](https://arxiv.org/abs/2602.17655v1)
- [Mine and Refine: Optimizing Graded Relevance in E-commerce Search Retrieval](https://arxiv.org/abs/2602.17654v1)
- [Differences in Typological Alignment in Language Models' Treatment of Differential Argument Marking](https://arxiv.org/abs/2602.17653v1)
- [Multi-Round Human-AI Collaboration with User-Specified Requirements](https://arxiv.org/abs/2602.17646v1)
- [Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting](https://arxiv.org/abs/2602.17645v1)
- [A.R.I.S.: Automated Recycling Identification System for E-Waste Classification Using Deep Learning](https://arxiv.org/abs/2602.17642v1)
- [FAMOSE: A ReAct Approach to Automated Feature Discovery](https://arxiv.org/abs/2602.17641v1)
- [When to Trust the Cheap Check: Weak and Strong Verification for Reasoning](https://arxiv.org/abs/2602.17633v1)
- [SMAC: Score-Matched Actor-Critics for Robust Offline-to-Online Transfer](https://arxiv.org/abs/2602.17632v1)
- [Catastrophic Forgetting Resilient One-Shot Incremental Federated Learning](https://arxiv.org/abs/2602.17625v1)
- [Unmasking the Factual-Conceptual Gap in Persian Language Models](https://arxiv.org/abs/2602.17623v1)
- [Stable Asynchrony: Variance-Controlled Off-Policy RL for LLMs](https://arxiv.org/abs/2602.17616v1)
- [Guarding the Middle: Protecting Intermediate Representations in Federated Split Learning](https://arxiv.org/abs/2602.17614v1)
- [Towards Anytime-Valid Statistical Watermarking](https://arxiv.org/abs/2602.17608v1)
- [AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing](https://arxiv.org/abs/2602.17607v1)
- [Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery](https://arxiv.org/abs/2602.17605v1)
- [SOLVAR: Fast covariance-based heterogeneity analysis with pose refinement for cryo-EM](https://arxiv.org/abs/2602.17603v1)
- [MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models](https://arxiv.org/abs/2602.17602v1)
- [The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\rightarrow$LLM Pipelines?](https://arxiv.org/abs/2602.17598v1)
- [Asymptotically Optimal Sequential Testing with Markovian Data](https://arxiv.org/abs/2602.17587v1)
- [Canonicalizing Multimodal Contrastive Representation Learning](https://arxiv.org/abs/2602.17584v1)
- [Be Wary of Your Time Series Preprocessing](https://arxiv.org/abs/2602.17568v1)
- [A Hybrid Federated Learning Based Ensemble Approach for Lung Disease Diagnosis Leveraging Fusion of SWIN Transformer and CNN](https://arxiv.org/abs/2602.17566v1)
- [Optimal Unconstrained Self-Distillation in Ridge Regression: Strict Improvements, Precise Asymptotics, and One-Shot Tuning](https://arxiv.org/abs/2602.17565v1)
- [Revisiting Weight Regularization for Low-Rank Continual Learning](https://arxiv.org/abs/2602.17559v1)
- [Probability-Invariant Random Walk Learning on Gyral Folding-Based Cortical Similarity Networks for Alzheimer's and Lewy Body Dementia Diagnosis](https://arxiv.org/abs/2602.17557v1)
- [KLong: Training LLM Agent for Extremely Long-horizon Tasks](https://arxiv.org/abs/2602.17547v1)
- [Adaptive Decentralized Composite Optimization via Three-Operator Splitting](https://arxiv.org/abs/2602.17545v1)
- [genriesz: A Python Package for Automatic Debiased Machine Learning with Generalized Riesz Regression](https://arxiv.org/abs/2602.17543v1)
- [Systematic Evaluation of Single-Cell Foundation Model Interpretability Reveals Attention Captures Co-Expression Rather Than Unique Regulatory Signal](https://arxiv.org/abs/2602.17532v1)
- [Provably Explaining Neural Additive Models](https://arxiv.org/abs/2602.17530v1)
- [Enhancing Large Language Models (LLMs) for Telecom using Dynamic Knowledge Graphs and Explainable Retrieval-Augmented Generation](https://arxiv.org/abs/2602.17529v1)
- [The Anxiety of Influence: Bloom Filters in Transformer Attention Heads](https://arxiv.org/abs/2602.17526v1)
- [LORA-CRAFT: Cross-layer Rank Adaptation via Frozen Tucker Decomposition of Pre-trained Attention Weights](https://arxiv.org/abs/2602.17510v1)
- [Retrospective In-Context Learning for Temporal Credit Assignment with Large Language Models](https://arxiv.org/abs/2602.17497v1)
- [Learning with Boolean threshold functions](https://arxiv.org/abs/2602.17493v1)
- [Linear Convergence in Games with Delayed Feedback via Extra Prediction](https://arxiv.org/abs/2602.17486v1)
- [Tracing Copied Pixels and Regularizing Patch Affinity in Copy Detection](https://arxiv.org/abs/2602.17484v1)
- [What Do LLMs Associate with Your Name? A Human-Centered Black-Box Audit of Personal Data](https://arxiv.org/abs/2602.17483v1)
- [Variational Grey-Box Dynamics Matching](https://arxiv.org/abs/2602.17477v1)
- [Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian](https://arxiv.org/abs/2602.17475v1)
- [Auditing Reciprocal Sentiment Alignment: Inversion Risk, Dialect Representation and Intent Misalignment in Transformers](https://arxiv.org/abs/2602.17469v1)
- [PEACE 2.0: Grounded Explanations and Counter-Speech for Combating Hate Expressions](https://arxiv.org/abs/2602.17467v1)
- [Entropy-Based Data Selection for Language Models](https://arxiv.org/abs/2602.17465v1)
- [Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge](https://arxiv.org/abs/2602.17452v1)
- [Beyond Pipelines: A Fundamental Study on the Rise of Generative-Retrieval Architectures in Web Research](https://arxiv.org/abs/2602.17450v1)
- [ABCD: All Biases Come Disguised](https://arxiv.org/abs/2602.17445v1)
- [AIDG: Evaluating Asymmetry Between Information Extraction and Containment in Multi-Turn Dialogue](https://arxiv.org/abs/2602.17443v1)
- [WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation](https://arxiv.org/abs/2602.17442v1)
- [Fine-Grained Uncertainty Quantification for Long-Form Language Model Outputs: A Comparative Study](https://arxiv.org/abs/2602.17431v1)
- [Evaluating Extremely Low-Resource Machine Translation: A Comparative Study of ChrF++ and BLEU Metrics](https://arxiv.org/abs/2602.17425v1)
- [Diverse Word Choices, Same Reference: Annotating Lexically-Rich Cross-Document Coreference](https://arxiv.org/abs/2602.17424v1)
- [Convergence Analysis of Two-Layer Neural Networks under Gaussian Input Masking](https://arxiv.org/abs/2602.17423v1)
- [A Privacy by Design Framework for Large Language Model-Based Applications for Children](https://arxiv.org/abs/2602.17418v1)
- [DAVE: A Policy-Enforcing LLM Spokesperson for Secure Multi-Document Data Sharing](https://arxiv.org/abs/2602.17413v1)
- [Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers](https://arxiv.org/abs/2602.17410v1)
- [A Contrastive Variational AutoEncoder for NSCLC Survival Prediction with Missing Modalities](https://arxiv.org/abs/2602.17402v1)
- [A High-Level Survey of Optical Remote Sensing](https://arxiv.org/abs/2602.17397v1)
- [SpectralGCD: Spectral Concept Selection and Cross-modal Representation Learning for Generalized Category Discovery](https://arxiv.org/abs/2602.17395v1)
- [Voice-Driven Semantic Perception for UAV-Assisted Emergency Networks](https://arxiv.org/abs/2602.17394v1)
- [Visual Model Checking: Graph-Based Inference of Visual Routines for Image Retrieval](https://arxiv.org/abs/2602.17386v1)
- [Dataless Weight Disentanglement in Task Arithmetic via Kronecker-Factored Approximate Curvature](https://arxiv.org/abs/2602.17385v1)
- [The Role of the Availability Heuristic in Multiple-Choice Answering Behaviour](https://arxiv.org/abs/2602.17377v1)
- [MDP Planning as Policy Inference](https://arxiv.org/abs/2602.17375v1)
- [RPDR: A Round-trip Prediction-Based Data Augmentation Framework for Long-Tail Question Answering](https://arxiv.org/abs/2602.17366v1)
- [A feature-stable and explainable machine learning framework for trustworthy decision-making under incomplete clinical data](https://arxiv.org/abs/2602.17364v1)
- [2Mamba2Furious: Linear in Complexity, Competitive in Accuracy](https://arxiv.org/abs/2602.17363v1)
- [Shortcut learning in geometric knot classification](https://arxiv.org/abs/2602.17350v1)
- [Partial Optimality in the Preordering Problem](https://arxiv.org/abs/2602.17346v1)
- [What Breaks Embodied AI Security:LLM Vulnerabilities, CPS Flaws,or Something Else?](https://arxiv.org/abs/2602.17345v1)
- [From Subtle to Significant: Prompt-Driven Self-Improving Optimization in Test-Time Graph OOD Detection](https://arxiv.org/abs/2602.17342v1)
- [SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework](https://arxiv.org/abs/2602.17330v1)
- [WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval](https://arxiv.org/abs/2602.17327v1)
- [The Sound of Death: Deep Learning Reveals Vascular Damage from Carotid Ultrasound](https://arxiv.org/abs/2602.17321v1)
- [Same Meaning, Different Scores: Lexical and Syntactic Sensitivity in LLM Evaluation](https://arxiv.org/abs/2602.17316v1)
- [Flickering Multi-Armed Bandits](https://arxiv.org/abs/2602.17315v1)
- [Open Datasets in Learning Analytics: Trends, Challenges, and Best PRACTICE](https://arxiv.org/abs/2602.17314v1)
- [LexiSafe: Offline Safe Reinforcement Learning with Lexicographic Safety-Reward Hierarchy](https://arxiv.org/abs/2602.17312v1)
- [MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions](https://arxiv.org/abs/2602.17308v1)
- [ArXiv-to-Model: A Practical Study of Scientific LM Training](https://arxiv.org/abs/2602.17288v1)
- [Representation Collapse in Machine Translation Through the Lens of Angular Dispersion](https://arxiv.org/abs/2602.17287v1)
- [Efficient privacy loss accounting for subsampling and random allocation](https://arxiv.org/abs/2602.17284v1)
- [Towards Cross-lingual Values Assessment: A Consensus-Pluralism Perspective](https://arxiv.org/abs/2602.17283v1)
- [Quantum Scrambling Born Machine](https://arxiv.org/abs/2602.17281v1)
- [RLGT: A reinforcement learning framework for extremal graph theory](https://arxiv.org/abs/2602.17276v1)
- [Gaussian surrogates do well on Poisson inverse problems](https://arxiv.org/abs/2602.17274v1)
- [Federated Latent Space Alignment for Multi-user Semantic Communications](https://arxiv.org/abs/2602.17271v1)
- [Unified Latents (UL): How to train your latents](https://arxiv.org/abs/2602.17270v1)
- [Learning a Latent Pulse Shape Interface for Photoinjector Laser Systems](https://arxiv.org/abs/2602.17263v1)
- [Quantifying and Mitigating Socially Desirable Responding in LLMs: A Desirability-Matched Graded Forced-Choice Psychometric Study](https://arxiv.org/abs/2602.17262v1)
- [Structured Prototype-Guided Adaptation for EEG Foundation Models](https://arxiv.org/abs/2602.17251v1)
- [Web Verbs: Typed Abstractions for Reliable Task Composition on the Agentic Web](https://arxiv.org/abs/2602.17245v1)
- [CounterFlowNet: From Minimal Changes to Meaningful Counterfactual Explanations](https://arxiv.org/abs/2602.17244v1)
- [TAPO-Structured Description Logic for Information Behavior: Procedural and Oracle-Based Extensions](https://arxiv.org/abs/2602.17242v1)
- [All Leaks Count, Some Count More: Interpretable Temporal Contamination Detection in LLM Backtesting](https://arxiv.org/abs/2602.17234v1)
- [Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom's Taxonomy](https://arxiv.org/abs/2602.17229v1)
- [Privacy-Preserving Mechanisms Enable Cheap Verifiable Inference of LLMs](https://arxiv.org/abs/2602.17223v1)
- [Decoding the Human Factor: High Fidelity Behavioral Prediction for Strategic Foresight](https://arxiv.org/abs/2602.17222v1)
- [From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences](https://arxiv.org/abs/2602.17221v1)
- [Continual learning and refinement of causal models through dynamic predicate invention](https://arxiv.org/abs/2602.17217v1)
- [Extending quantum theory with AI-assisted deterministic game theory](https://arxiv.org/abs/2602.17213v1)
- [MGD: Moment Guided Diffusion for Maximum Entropy Generation](https://arxiv.org/abs/2602.17211v1)
- [SoftDTW-CUDA-Torch: Memory-Efficient GPU-Accelerated Soft Dynamic Time Warping for PyTorch](https://arxiv.org/abs/2602.17206v1)
- [Deeper detection limits in astronomical imaging using self-supervised spatiotemporal denoising](https://arxiv.org/abs/2602.17205v1)
- [What Makes a Good Doctor Response? An Analysis on a Romanian Telemedicine Platform](https://arxiv.org/abs/2602.17194v1)
- [Texo: Formula Recognition within 20M Parameters](https://arxiv.org/abs/2602.17189v1)
- [Anti-causal domain generalization: Leveraging unlabeled data](https://arxiv.org/abs/2602.17187v1)
- [The Bots of Persuasion: Examining How Conversational Agents' Linguistic Expressions of Personality Affect User Perceptions and Decisions](https://arxiv.org/abs/2602.17185v1)
- [Robustness and Reasoning Fidelity of Large Language Models in Long-Context Code Question Answering](https://arxiv.org/abs/2602.17183v1)
- [Continual uncertainty learning](https://arxiv.org/abs/2602.17174v1)
- [In-Context Learning in Linear vs. Quadratic Attention Models: An Empirical Study on Regression Tasks](https://arxiv.org/abs/2602.17171v1)
- [JEPA-DNA: Grounding Genomic Foundation Models through Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.17162v1)
- [Powering Up Zeroth-Order Training via Subspace Gradient Orthogonalization](https://arxiv.org/abs/2602.17155v1)
- [TimeOmni-VL: Unified Models for Time Series Understanding and Generation](https://arxiv.org/abs/2602.17149v1)
- [Bonsai: A Framework for Convolutional Neural Network Acceleration Using Criterion-Based Pruning](https://arxiv.org/abs/2602.17145v1)
- [When More Experts Hurt: Underfitting in Multi-Expert Learning to Defer](https://arxiv.org/abs/2602.17144v1)
- [VP-VAE: Rethinking Vector Quantization via Adaptive Vector Perturbation](https://arxiv.org/abs/2602.17133v1)
- [Efficient Parallel Algorithm for Decomposing Hard CircuitSAT Instances](https://arxiv.org/abs/2602.17130v1)
- [The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for Auditing Latent Bias and Compounding Risk in Generative AI](https://arxiv.org/abs/2602.17127v1)
- [3D Scene Rendering with Multimodal Gaussian Splatting](https://arxiv.org/abs/2602.17124v1)
- [TIFO: Time-Invariant Frequency Operator for Stationarity-Aware Representation Learning in Time Series](https://arxiv.org/abs/2602.17122v1)
- [i-PhysGaussian: Implicit Physical Simulation for 3D Gaussian Splatting](https://arxiv.org/abs/2602.17117v1)
- [Epistemology of Generative AI: The Geometry of Knowing](https://arxiv.org/abs/2602.17116v1)
- [Semi-Supervised Learning on Graphs using Graph Neural Networks](https://arxiv.org/abs/2602.17115v1)
- [Instructor-Aligned Knowledge Graphs for Personalized Learning](https://arxiv.org/abs/2602.17111v1)
- [Projective Psychological Assessment of Large Multimodal Models Using Thematic Apperception Tests](https://arxiv.org/abs/2602.17108v1)
- [Owen-based Semantics and Hierarchy-Aware Explanation (O-Shap)](https://arxiv.org/abs/2602.17107v1)
- [Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Framework for Benchmark Dataset Construction](https://arxiv.org/abs/2602.17106v1)
- [Simplify to Amplify: Achieving Information-Theoretic Bounds with Fewer Steps in Spectral Community Detection](https://arxiv.org/abs/2602.17104v1)
- [Online Learning with Improving Agents: Multiclass, Budgeted Agents and Bandit Learners](https://arxiv.org/abs/2602.17103v1)
- [Operationalization of Machine Learning with Serverless Architecture: An Industrial Operationalization of Machine Learning with Serverless Architecture: An Industrial Implementation for Harmonized System Code Prediction](https://arxiv.org/abs/2602.17102v1)
- [Deep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative Study with Mean-Variance Optimization](https://arxiv.org/abs/2602.17098v1)
- [Agentic Wireless Communication for 6G: Intent-Aware and Continuously Evolving Physical-Layer Intelligence](https://arxiv.org/abs/2602.17096v1)
- [FLoRG: Federated Fine-tuning with Low-rank Gram Matrices and Procrustes Alignment](https://arxiv.org/abs/2602.17095v1)
- [A Locality Radius Framework for Understanding Relational Inductive Bias in Database Learning](https://arxiv.org/abs/2602.17092v1)
- [MeGU: Machine-Guided Unlearning with Target Feature Disentanglement](https://arxiv.org/abs/2602.17088v1)
- [Dynamic Decision-Making under Model Misspecification: A Stochastic Stability Approach](https://arxiv.org/abs/2602.17086v1)
- [How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses](https://arxiv.org/abs/2602.17084v1)
- [Adam Improves Muon: Adaptive Moment Estimation with Orthogonalized Momentum](https://arxiv.org/abs/2602.17080v1)
- [BankMathBench: A Benchmark for Numerical Reasoning in Banking Scenarios](https://arxiv.org/abs/2602.17072v1)
- [AdvSynGNN: Structure-Adaptive Graph Neural Nets via Adversarial Synthesis and Self-Corrective Propagation](https://arxiv.org/abs/2602.17071v1)
- [General sample size analysis for probabilities of causation: a delta method approach](https://arxiv.org/abs/2602.17070v1)
- [Spatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control](https://arxiv.org/abs/2602.17068v1)
- [Predictive Batch Scheduling: Accelerating Language Model Training Through Loss-Aware Sample Prioritization](https://arxiv.org/abs/2602.17066v1)
- [Sign Lock-In: Randomly Initialized Weight Signs Persist and Bottleneck Sub-Bit Model Compression](https://arxiv.org/abs/2602.17063v1)
- [Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.17062v1)
- [ALPS: A Diagnostic Challenge Set for Arabic Linguistic & Pragmatic Reasoning](https://arxiv.org/abs/2602.17054v1)
- [RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Reasoning Models](https://arxiv.org/abs/2602.17053v1)
- [Evaluating Cross-Lingual Classification Approaches Enabling Topic Discovery for Multilingual Social Media Data](https://arxiv.org/abs/2602.17051v1)
- [Multi-Probe Zero Collision Hash (MPZCH): Mitigating Embedding Collisions and Enhancing Model Freshness in Large-Scale Recommenders](https://arxiv.org/abs/2602.17050v1)
- [IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents](https://arxiv.org/abs/2602.17049v1)
- [Large Language Models Persuade Without Planning Theory of Mind](https://arxiv.org/abs/2602.17045v1)
- [Phase-Aware Mixture of Experts for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.17038v1)
- [Wink: Recovering from Misbehaviors in Coding Agents](https://arxiv.org/abs/2602.17037v1)
- [LiveGraph: Active-Structure Neural Re-ranking for Exercise Recommendation](https://arxiv.org/abs/2602.17036v1)
- [Forecasting Anomaly Precursors via Uncertainty-Aware Time-Series Ensembles](https://arxiv.org/abs/2602.17028v1)
- [Transforming Behavioral Neuroscience Discovery with In-Context Learning and AI-Enhanced Tensor Methods](https://arxiv.org/abs/2602.17027v1)
- [WS-GRPO: Weakly-Supervised Group-Relative Policy Optimization for Rollout-Efficient Reasoning](https://arxiv.org/abs/2602.17025v1)
- [ReIn: Conversational Error Recovery with Reasoning Inception](https://arxiv.org/abs/2602.17022v1)
- [M2F: Automated Formalization of Mathematical Literature at Scale](https://arxiv.org/abs/2602.17016v1)
- [Action-Graph Policies: Learning Action Co-dependencies in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.17009v1)
- [Arcee Trinity Large Technical Report](https://arxiv.org/abs/2602.17004v1)
- [Persona2Web: Benchmarking Personalized Web Agents for Contextual Reasoning with User History](https://arxiv.org/abs/2602.17003v1)
- [Sonar-TS: Search-Then-Verify Natural Language Querying for Time Series Databases](https://arxiv.org/abs/2602.17001v1)
- [Exploring LLMs for User Story Extraction from Mockups](https://arxiv.org/abs/2602.16997v1)
- [Dynamic Delayed Tree Expansion For Improved Multi-Path Speculative Decoding](https://arxiv.org/abs/2602.16994v1)
- [Conv-FinRe: A Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation](https://arxiv.org/abs/2602.16990v1)
- [Fundamental Limits of Black-Box Safety Evaluation: Information-Theoretic and Computational Barriers from Latent Context Conditioning](https://arxiv.org/abs/2602.16984v1)
- [Discovering Universal Activation Directions for PII Leakage in Language Models](https://arxiv.org/abs/2602.16980v1)
- [Characterizing the Predictive Impact of Modalities with Supervised Latent-Variable Modeling](https://arxiv.org/abs/2602.16979v1)
- [Fail-Closed Alignment for Large Language Models](https://arxiv.org/abs/2602.16977v1)

_…and 13 more._

</details>

<details><summary>Search definitions</summary>

- Materials & Physics (cond-mat / comp-ph / chem-ph) — `cat:cond-mat.mtrl-sci OR cat:physics.comp-ph OR cat:physics.chem-ph`
- AI/ML (cs.AI/cs.LG/stat.ML/cs.CL) — `cat:cs.AI OR cat:cs.LG OR cat:stat.ML OR cat:cs.CL`

</details>
