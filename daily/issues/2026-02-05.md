---
title: "Daily Issue (JST): 2026-02-05"
---

# Daily Issue (JST): 2026-02-05

## What's New Today

**AI Agents, Efficient Training, and Quantum Materials Lead Daily Research**

Today's research spans efficient AI agent design, novel training paradigms, and advances in quantum materials simulation. Agentic systems show progress in long-horizon reasoning and robustness, while new methods aim to compress models and accelerate training. In materials science, studies probe magnetic anisotropy, phase transitions, and quantum circuit design.

**Highlights**
- Agent frameworks improve long-horizon reasoning via hierarchical retrieval and proactive intent discovery.
- New training methods address efficiency via visual token pruning, weight update sparsity, and quantization-aware regularization.
- Studies of magnetic thin films and quasicrystal defects reveal insights into anisotropy and thermodynamic stability.
- Quantum circuit design advances through neuro-evolution and symmetry-adapted variational solvers.
- Retrieval-augmented generation systems are optimized for robustness and low-resource deployment.
- Continual and federated learning methods enhance stability and fairness in distributed settings.

**Themes**
- AI: Agentic Systems & Reasoning
- AI: Efficient Training & Inference
- Materials: Quantum & Magnetic Phenomena
- AI: Retrieval & Knowledge Grounding
- Cross-Domain: Quantum Computing & Simulation

**Keywords**
- multi-agent systems
- efficient training
- retrieval-augmented generation
- magnetic anisotropy
- quantum circuits
- continual learning
- diffusion models
- reasoning
- knowledge graphs
- federated learning
- phase transitions
- model compression

**Total new papers:** 234

## Featured Papers

### [PLATE: Plasticity-Tunable Efficient Adapters for Geometry-Aware Continual Learning](https://arxiv.org/abs/2602.03846v1)
**Authors:** Romain Cosentino
**Published:** 2026-02-03
**Summary:** PLATE is a continual learning method that adapts pretrained models without old-task data by exploiting geometric redundancy to control plasticity and retention via structured low-rank updates.

**What's new**
- Uses geometric redundancy in pretrained networks to create protected update subspaces without old data.
- Restricts updates to redundant neurons to minimize functional drift and improve worst-case retention.
- Introduces structured low-rank updates where only a small matrix is trained, freezing others from pretrained weights.
- Provides explicit tunable control over the plasticity-retention trade-off in continual learning.

### [Parallel-Probe: Towards Efficient Parallel Thinking via 2D Probing](https://arxiv.org/abs/2602.03845v1)
**Authors:** Tong Zheng, Chengsong Huang, Runpeng Dai, Yun He, Rui Liu, Xin Ni, Huiwen Bao, Kaishen Wang, Hongtu Zhu, Jiaxin Huang, Furong Huang, Heng Huang
**Published:** 2026-02-03
**Summary:** A training-free controller that optimizes parallel reasoning by dynamically pruning branches and stopping early based on consensus, cutting token costs by over 25% while maintaining accuracy.

**What's new**
- Introduces 2D probing to expose width-depth dynamics in parallel thinking by sampling intermediate answers from all branches.
- Reveals key insights: non-monotonic scaling, heterogeneous branch lengths, and early global consensus stabilization.
- Proposes Parallel-Probe, which uses consensus-based early stopping and deviation-based pruning to optimize width and depth online.
- Reduces sequential tokens by up to 35.8% and total token cost by over 25.8% while keeping competitive accuracy versus majority voting.

### [Classical Benchmarks of a Symmetry-Adapted Variational Quantum Eigensolver for Real-Time Green's Functions in Dynamical Mean-Field Theory](https://arxiv.org/abs/2602.03843v1)
**Authors:** Aadi Singh, Chakradhar Rangi, Ka-Ming Tam
**Published:** 2026-02-03
**Summary:** A symmetry-adapted VQE accurately computes ground states and real-time Green's functions for DMFT impurity models beyond minimal two-site approximations, especially in strong coupling.

**What's new**
- Introduces a symmetry-adapted VQE ansatz enforcing particle number, spin projection, and total spin conservation for DMFT impurity models.
- Demonstrates accurate ground state energies (<0.01% error) and real-time Green's functions for four-site models with strong interactions.
- Shows that accurate ground state energy does not guarantee accurate dynamical properties, especially in weak coupling regimes.
- Extends quantum-classical hybrid DMFT beyond two-site approximations, offering a pathway for near-term quantum simulation of correlated materials.

### [Investigating Quantum Circuit Designs Using Neuro-Evolution](https://arxiv.org/abs/2602.03840v1)
**Authors:** Devroop Kar, Daniel Krutz, Travis Desell
**Published:** 2026-02-03
**Summary:** EXAQC uses evolutionary algorithms to automatically design and train quantum circuits, optimizing gate types, connectivity, and depth for specific problems and hardware.

**What's new**
- Proposes EXAQC, an evolutionary method for joint search over gate types, connectivity, parameterization, and circuit depth.
- Respects hardware and noise constraints, aiming for scalable and hardware-efficient quantum circuit design.
- Supports both Qiskit and Pennylane libraries, allowing full user configuration of the evolutionary process.
- Preliminary results show over 90% accuracy on classification tasks and high fidelity in state emulation.

### [Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL](https://arxiv.org/abs/2602.03839v1)
**Authors:** Erfan Miahi, Eugene Belilovsky
**Published:** 2026-02-03
**Summary:** PULSE exploits near-constant 99%+ sparsity in RL weight updates to enable lossless, 100x communication reduction for decentralized training via sparse encoding.

**What's new**
- Systematic study shows RL weight updates are consistently >99% sparse across training dynamics and model scales.
- Proposes PULSE, a lossless method transmitting only indices/values of modified parameters, avoiding floating-point drift.
- Achieves over 100x communication reduction (14 GB to ~108 MB) with bit-identical training performance.
- Enables decentralized RL to approach centralized throughput by reducing sync bandwidth from 20 Gbit/s to 0.2 Gbit/s.

### [PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization](https://arxiv.org/abs/2602.03838v1)
**Authors:** Erzhen Hu, Frederik Brudy, David Ledo, George Fitzmaurice, Fraser Anderson
**Published:** 2026-02-03
**Summary:** PrevizWhiz is a system that combines rough 3D scenes with generative AI models to create stylized video previews, lowering technical barriers for filmmakers in pre-production.

**What's new**
- Integrates rough 3D scenes with generative image/video models for stylized video previews
- Enables frame-level restyling with adjustable resemblance and time-based editing via motion paths
- Lowers technical barriers and accelerates creative iteration for filmmakers
- Surfaces challenges of continuity, authorship, and ethics in AI-assisted filmmaking

### [Accelerating Scientific Research with Gemini: Case Studies and Common Techniques](https://arxiv.org/abs/2602.03837v1)
**Authors:** David P. Woodruff, Vincent Cohen-Addad, Lalit Jain, Jieming Mao, Song Zuo, MohammadHossein Bateni, Simina Branzei, Michael P. Brenner, Lin Chen, Ying Feng, Lance Fortnow, Gang Fu, Ziyi Guan, Zahra Hadizadeh, Mohammad T. Hajiaghayi, Mahdi JafariRaviz, Adel Javanmard, Karthik C. S., Ken-ichi Kawarabayashi, Ravi Kumar, Silvio Lattanzi, Euiwoong Lee, Yi Li, Ioannis Panageas, Dimitris Paparas, Benjamin Przybocki, Bernardo Subercaseaux, Ola Svensson, Shayan Taherijam, Xuan Wu, Eylon Yogev, Morteza Zadimoghaddam, Samson Zhou, Vahab Mirrokni
**Published:** 2026-02-03
**Summary:** Case studies show how Gemini AI models collaborate with researchers to solve open problems and generate proofs in theoretical computer science and other fields.

**What's new**
- Demonstrates AI collaboration to solve open problems and refute conjectures in theoretical computer science, economics, and physics.
- Extracts techniques like iterative refinement and problem decomposition for effective human-AI collaboration in research.
- Highlights AI as an adversarial reviewer to detect subtle flaws in existing proofs.
- Describes a neuro-symbolic loop where AI autonomously writes and executes code to verify complex derivations.

### [AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations](https://arxiv.org/abs/2602.03828v1)
**Authors:** Minjun Zhu, Zhen Lin, Yixuan Weng, Panzhong Lu, Qiujie Xie, Yifan Wei, Sifan Liu, Qiyao Sun, Yue Zhang
**Published:** 2026-02-03
**Summary:** AutoFigure is an agentic framework that automatically generates and refines publication-ready scientific illustrations from long-form text, outperforming existing methods.

**What's new**
- Introduces FigureBench, the first large-scale benchmark with 3,300 text-figure pairs for scientific illustration generation.
- Proposes AutoFigure, the first agentic framework for generating scientific illustrations via thinking, recombination, and validation.
- AutoFigure produces layouts that are structurally sound and aesthetically refined, achieving publication-ready quality.
- Extensive experiments show AutoFigure consistently surpasses all baseline methods on the new benchmark.

### [Robust Intervention Learning from Emergency Stop Interventions](https://arxiv.org/abs/2602.03825v1)
**Authors:** Ethan Pronovost, Khimya Khetarpal, Siddhartha Srinivasa
**Published:** 2026-02-03
**Summary:** A method called RIFT uses emergency stop interventions to improve robot policies robustly by combining them with a prior policy to handle noisy or incomplete signals.

**What's new**
- Proposes Residual Intervention Fine-Tuning (RIFT) to learn from emergency stop interventions by combining them with a prior policy.
- Frames intervention learning as a fine-tuning problem to resolve ambiguity when intervention signals under-specify the task.
- Provides theoretical analysis on conditions for policy improvement and when intervention learning may fail.
- Shows experiments where RIFT enables robust policy improvement across various intervention strategies and prior qualities.

### [They Said Memes Were Harmless-We Found the Ones That Hurt: Decoding Jokes, Symbols, and Cultural References](https://arxiv.org/abs/2602.03822v1)
**Authors:** Sahil Tripathi, Gautam Siddharth Kashyap, Mehwish Nasim, Jian Yang, Jiechao Gao, Usman Naseem
**Published:** 2026-02-03
**Summary:** CROSS-ALIGN+ is a three-stage framework that improves meme-based abuse detection by incorporating cultural knowledge, sharpening decision boundaries, and providing explanations.

**What's new**
- Enriches multimodal meme representations with structured knowledge from ConceptNet, Wikidata, and Hatebase to address cultural blindness.
- Uses parameter-efficient LoRA adapters to reduce boundary ambiguity between satire and abuse.
- Enhances interpretability by generating cascaded explanations for model decisions.
- Demonstrates up to 17% relative F1 improvement over state-of-the-art methods across five benchmarks.

### [SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving](https://arxiv.org/abs/2602.03816v1)
**Authors:** Yesom Park, Annie C. Lu, Shao-Ching Huang, Qiyang Hu, Y. Sungtaek Ju, Stanley Osher
**Published:** 2026-02-03
**Summary:** SymPlex is a reinforcement learning framework that discovers analytical symbolic solutions to PDEs using a structure-aware Transformer for grammar-constrained, tree-structured generation.

**What's new**
- Formulates symbolic PDE solving as tree-structured decision-making, optimized solely via PDE and boundary conditions.
- Introduces SymFormer, a Transformer with tree-relative self-attention to model hierarchical symbolic dependencies.
- Employs grammar-constrained autoregressive decoding to ensure syntactic validity of generated expressions.
- Operates directly in symbolic expression space for interpretable, human-readable solutions with explicit parametric dependence.
- Demonstrates exact recovery of non-smooth and parametric PDE solutions using deep learning-based symbolic methods.

### [Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning](https://arxiv.org/abs/2602.03815v1)
**Authors:** Dingkun Zhang, Shuhan Qi, Yulin Wu, Xinyu Xiao, Xuan Wang, Long Chen
**Published:** 2026-02-03
**Summary:** A fast-slow training framework for multimodal LLMs that uses visual token pruning for efficiency while maintaining performance via a dual-mode and distillation approach.

**What's new**
- Proposes DualSpeed, a fast-slow training framework to address training-inference mismatch from visual token pruning.
- Fast-mode uses visual token pruning for efficiency; slow-mode trains on full sequences for consistency.
- Employs self-distillation from fast-mode to slow-mode to boost training and retain performance.
- Achieves 2.1x to 4.0x training speedup for LLaVA models while maintaining over 99% of original performance.

### [Vacancy defects in square-triangle tilings and their implications for quasicrystals formed by square-shoulder particles](https://arxiv.org/abs/2602.03813v1)
**Authors:** Alptuğ Ulugöl, Giovanni Del Monte, Eline K. Kempkes, Frank Smallenburg, Laura Filion
**Published:** 2026-02-03
**Summary:** Defects in square-triangle quasicrystals significantly boost configurational entropy, stabilizing the phase in soft-matter systems with square-shoulder particles.

**What's new**
- Developed a Monte Carlo method to compute configurational entropy of tilings with two types of hexagon defect tiles.
- Found each defect contributes more entropy than a vacancy in a periodic crystal, amplified by combinatorial mixing.
- Applied results to a square-shoulder particle model, predicting high equilibrium defect concentration in quasicrystals.
- Showed quasicrystalline phase contains more point defects than typical periodic crystals, explaining their prominence.

### [Antidistillation Fingerprinting](https://arxiv.org/abs/2602.03812v1)
**Authors:** Yixuan Even Xu, John Kirchenbauer, Yash Savani, Asher Trockman, Alexander Robey, Tom Goldstein, Fei Fang, J. Zico Kolter
**Published:** 2026-02-03
**Summary:** A method to detect if a student LLM was trained on a teacher's outputs by sampling tokens that maximize fingerprint detectability after fine-tuning.

**What's new**
- Aligns fingerprinting objective with student learning dynamics via gradient-based antidistillation sampling.
- Uses a proxy model to sample tokens maximizing expected fingerprint detectability post-fine-tuning.
- Achieves stronger detection confidence with minimal utility loss versus heuristic baselines.
- Effective even when the student model's architecture is unknown.

### [Enhancing Imbalanced Node Classification via Curriculum-Guided Feature Learning and Three-Stage Attention Network](https://arxiv.org/abs/2602.03808v1)
**Authors:** Abdul Joseph Fofanah, Lian Wen, David Chen, Shaoyang Zhang
**Published:** 2026-02-03
**Summary:** CL3AN-GNN improves imbalanced node classification in graphs using a curriculum-guided three-stage attention network (Engage, Enact, Embed) to learn from simple to complex features.

**What's new**
- Introduces a three-stage attention mechanism (Engage, Enact, Embed) mimicking human learning for imbalanced graphs.
- Uses curriculum learning, starting with simple features like 1-hop patterns before complex multi-hop relations.
- Shows consistent gains in accuracy, F1, and AUC across eight diverse benchmark datasets.
- Provides interpretability via gradient stability and attention correlation learning curves.

### [Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation](https://arxiv.org/abs/2602.03806v1)
**Authors:** Ziru Chen, Dongdong Chen, Ruinan Jin, Yingbin Liang, Yujia Xie, Huan Sun
**Published:** 2026-02-03
**Summary:** Cobalt is a contextual bandit method that combines offline trajectories with online learning to efficiently train LLMs for multi-turn code generation.

**What's new**
- Formulates multi-turn code generation as a one-step recoverable MDP, enabling contextual bandit learning.
- Uses offline trajectories from a reference LLM as prompts for online single-step completion training.
- Outperforms online RL baselines like GRPO and VeRPO, boosting Pass@1 scores on LiveCodeBench by up to 9.0 points.
- Mitigates in-context reward hacking by augmenting training with perturbed trajectories.

### [Origin of mixed anisotropy in crystalline Permalloy and amorphous Cobalt thin films individually deposited on Si substrate](https://arxiv.org/abs/2602.03804v1)
**Authors:** Kirti Kirti, Baisali Ghadai, Abinash Mishra, Rahulkrishnan R, Sucheta Mondal
**Published:** 2026-02-03
**Summary:** Investigates how mixed magnetic anisotropies evolve with thickness in sputter-deposited crystalline Permalloy and amorphous Cobalt films on silicon, causing a tilt in the magnetization easy axis.

**What's new**
- Compares mixed anisotropy evolution in crystalline fcc-Py vs. amorphous a-Co films on Si(100) across thickness ranges.
- Observes an alteration of the easy magnetization axis from purely in-plane due to collective mixed anisotropy effects.
- Links specific anisotropy regimes to film growth conditions and categorizes samples based on dominant anisotropy and tilt direction.
- Demonstrates thickness-dependent emergence of mixed anisotropies in both material systems using XRD, AFM, and VSM.
- Provides a direct comparison beneficial for spintronics, where magnetization tilt can improve device performance.

### [Do We Need Asynchronous SGD? On the Near-Optimality of Synchronous Methods](https://arxiv.org/abs/2602.03802v1)
**Authors:** Grigory Begunov, Alexander Tyurin
**Published:** 2026-02-03
**Summary:** Synchronous SGD methods are theoretically near-optimal for many heterogeneous distributed learning scenarios, challenging the need for asynchronous approaches.

**What's new**
- Shows synchronous SGD and its robust variant are nearly optimal under random computation times and adversarial worker participation.
- Proves time complexities are optimal up to logarithmic factors in many practical heterogeneous regimes.
- Finds synchronous methods sufficient for many modern scenarios, though asynchronous ones remain necessary for some tasks.

### [Conformal Reachability for Safe Control in Unknown Environments](https://arxiv.org/abs/2602.03799v1)
**Authors:** Xinhang Ma, Junlin Wu, Yiannis Kantaros, Yevgeniy Vorobeychik
**Published:** 2026-02-03
**Summary:** A framework combining conformal prediction and reachability analysis to provide probabilistic safety guarantees for control policies in unknown dynamical systems.

**What's new**
- Uses conformal prediction to obtain valid uncertainty intervals for unknown system dynamics at each time step.
- Performs reachability analysis to verify safety within the conformal uncertainty bounds.
- Trains control policies that optimize reward while maximizing the planning horizon with safety guarantees.
- Evaluated across seven settings in four domains (cartpole, lane following, drone, navigation) for affine and nonlinear safety specs.

### [FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation](https://arxiv.org/abs/2602.03798v1)
**Authors:** Zimu Lu, Houxing Ren, Yunqiao Yang, Ke Wang, Zhuofan Zong, Mingjie Zhan, Hongsheng Li
**Published:** 2026-02-03
**Summary:** A unified agent system for full-stack web development that combines a multi-agent coding framework, a repository back-translation learning method, and a comprehensive testing benchmark.

**What's new**
- Introduces FullStack-Dev, a multi-agent framework for planning, editing, navigating codebases, and localizing bugs in full-stack apps.
- Proposes FullStack-Learn, a data-scaling method that back-translates website repositories to self-improve the backbone LLM.
- Presents FullStack-Bench, a benchmark that systematically tests frontend, backend, and database functionalities of generated websites.
- Outperforms prior state-of-the-art by 8.7% (frontend), 38.2% (backend), and 15.9% (database) on test cases.
- Shows self-improvement raises a 30B model's performance by 9.7%, 9.5%, and 2.8% on the three test sets via back-translation.

### [Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity](https://arxiv.org/abs/2602.03794v1)
**Authors:** Yingxuan Yang, Chengrui Qu, Muning Wen, Laixi Shi, Ying Wen, Weinan Zhang, Adam Wierman, Shangding Gu
**Published:** 2026-02-03
**Summary:** Scaling LLM-based multi-agent systems with homogeneous agents yields diminishing returns, but introducing diversity (different models/prompts) unlocks substantial gains by accessing more effective information channels.

**What's new**
- Identifies diminishing returns in scaling homogeneous agents, while heterogeneous agents yield substantial gains.
- Proves performance is bounded by task uncertainty, not agent count, using an information-theoretic framework.
- Introduces K*, a metric to quantify effective channels without ground-truth labels.
- Shows 2 diverse agents can match or exceed 16 homogeneous agents in empirical evaluations.

### [Should I use Synthetic Data for That? An Analysis of the Suitability of Synthetic Data for Data Sharing and Augmentation](https://arxiv.org/abs/2602.03791v1)
**Authors:** Bogdan Kulynych, Theresa Stadler, Jean Louis Raisaro, Carmela Troncoso
**Published:** 2026-02-03
**Summary:** A formal analysis revealing fundamental and practical limits of synthetic data for data sharing and augmentation, showing many envisioned use cases are a poor fit.

**What's new**
- Formalizes three key use cases: sharing as a privacy proxy, augmenting ML training, and reducing statistical variance.
- Identifies fundamental constraints that make synthetic data unsuitable for many existing or envisioned applications.
- Provides a framework for decision-makers to assess if synthetic data fits their specific data availability problem.

### [Fast Sampling for Flows and Diffusions with Lazy and Point Mass Stochastic Interpolants](https://arxiv.org/abs/2602.03789v1)
**Authors:** Gabriel Damsholt, Jes Frellsen, Susanne Ditlevsen
**Published:** 2026-02-03
**Summary:** A method to convert sample paths between different interpolation schedules in generative models, enabling faster image generation without retraining.

**What's new**
- Proves conversion of SDE sample paths between arbitrary schedules and diffusion coefficients
- Extends stochastic interpolant framework to include point mass schedules
- Identifies lazy schedule families that make the drift identically zero for Gaussian data
- Shows deterministic sampling yields variance-preserving schedules, optimal SDE yields point mass
- Applies lazy schedule conversion to pretrained flow models for faster image generation

### [AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration](https://arxiv.org/abs/2602.03786v1)
**Authors:** Jianhao Ruan, Zhihao Xu, Yiran Peng, Fashen Ren, Zhaoyang Yu, Xinbing Liang, Jinyu Xiang, Bang Liu, Chenglin Wu, Yuyu Luo, Jiayi Zhang
**Published:** 2026-02-03
**Summary:** AOrchestra is a framework that automatically creates specialized sub-agents on demand for complex tasks, improving adaptability and performance.

**What's new**
- Introduces a unified agent abstraction as a tuple (Instruction, Context, Tools, Model) for dynamic sub-agent creation.
- Central orchestrator automatically creates specialized executors per task step, reducing manual engineering.
- Enables controllable performance-cost trade-offs, aiming for Pareto efficiency in agent systems.
- Achieves 16.28% relative improvement on benchmarks like GAIA and SWE-Bench with Gemini-3-Flash.

<details><summary>More papers (210)</summary>

**Materials & Physics (cond-mat / comp-ph / chem-ph)**
- [The Mpemba effect in the Descartes protocol: A time-delayed Newton's law of cooling approach](https://arxiv.org/abs/2602.03790v1)
- [Polytype-Dependent Upconversion Photoluminescence in 3R-MoS2](https://arxiv.org/abs/2602.03780v1)
- [Ultrastable 2D glasses and packings explained by local centrosymmetry](https://arxiv.org/abs/2602.03770v1)
- [Transformation front kinetics in deformable ferromagnets](https://arxiv.org/abs/2602.03745v1)
- [Role of magnon-magnon interaction in optical excitation of coherent two-magnon modes](https://arxiv.org/abs/2602.03697v1)
- [Ab initio Phase Diagram of Ta2O5](https://arxiv.org/abs/2602.03649v1)
- [A Method for Thermal Radiation Transport Using Backward Characteristic Tracing](https://arxiv.org/abs/2602.03621v1)
- [Evidence for Many-Body States in NiPS$_3$ Revealed by Angle-Resolved Photoelectron Spectroscopy](https://arxiv.org/abs/2602.03600v1)
- [Radial gradient of superionic hydrogen in Earth's inner core](https://arxiv.org/abs/2602.03509v1)
- [Skyrmions in 2D chiral magnets with noncollinear ground states stabilized by higher-order interactions](https://arxiv.org/abs/2602.03487v1)
- [Emergent 3D Fermiology and Magnetism in an Intercalated Van der Waals System](https://arxiv.org/abs/2602.03457v1)
- [Acceleration of Atomistic NEGF: Algorithms, Parallelization, and Machine Learning](https://arxiv.org/abs/2602.03438v1)
- [Single-Atom Adsorption on h-BN along the Periodic Table of Elements: From Pristine Surface to Vacancy-Engineered Sites](https://arxiv.org/abs/2602.03424v1)
- [Neural Hodge Corrective Solvers: A Hybrid Iterative-Neural Framework](https://arxiv.org/abs/2602.03404v1)
- [Accelerating Complex Materials Discovery with Universal Machine-Learning Potential-Driven Structure Prediction](https://arxiv.org/abs/2602.03369v1)
- [Information-Theoretic Multi-Model Fusion for Target-Oriented Adaptive Sampling in Materials Design](https://arxiv.org/abs/2602.03319v1)
- [A third law of thermodynamics is an unnecessary complexity](https://arxiv.org/abs/2602.03244v1)
- [Simultaneous measurement of Raman and nonlinear optical tensors](https://arxiv.org/abs/2602.03196v1)
- [Fully Automated Adaptive Parameter Selection for 3-D High-order Nyström Boundary Integral Equation Methods](https://arxiv.org/abs/2602.03178v1)
- [Intrinsically DRC-Compliant Nanophotonic Design via Learned Generative Manifolds](https://arxiv.org/abs/2602.03142v1)
- [Electron chirality and hydrodynamic helicity: Analysis in the atomic limit](https://arxiv.org/abs/2602.03125v1)
- [Impact of Local Descriptors Derived from Machine Learning Potentials in Graph Neural Networks for Molecular Property Prediction](https://arxiv.org/abs/2602.03046v1)
- [Ferroelectric dynamic-field-driven nucleation and growth model for predictive materials-to-circuit co-design](https://arxiv.org/abs/2602.02957v1)

**AI/ML (cs.AI/cs.LG/stat.ML/cs.CL)**
- [Preference-based Conditional Treatment Effects and Policy Learning](https://arxiv.org/abs/2602.03823v1)
- [Adaptive Evidence Weighting for Audio-Spatiotemporal Fusion](https://arxiv.org/abs/2602.03817v1)
- [Conformal Thinking: Risk Control for Reasoning on a Compute Budget](https://arxiv.org/abs/2602.03814v1)
- [Prediction of Critical Heat Flux in Rod Bundles Using Tube-Based Hybrid Machine Learning Models in CTF](https://arxiv.org/abs/2602.03805v1)
- [Manifold Random Features](https://arxiv.org/abs/2602.03797v1)
- [WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents](https://arxiv.org/abs/2602.03792v1)
- [Inference-time Unlearning Using Conformal Prediction](https://arxiv.org/abs/2602.03787v1)
- [Context Compression via Explicit Information Transmission](https://arxiv.org/abs/2602.03784v1)
- [Efficient Estimation of Kernel Surrogate Models for Task Attribution](https://arxiv.org/abs/2602.03783v1)
- [Reward Redistribution for CVaR MDPs using a Bellman Operator on L-infinity](https://arxiv.org/abs/2602.03778v1)
- [DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books](https://arxiv.org/abs/2602.03776v1)
- [An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents](https://arxiv.org/abs/2602.03775v1)
- [Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL](https://arxiv.org/abs/2602.03773v1)
- [UniGeM: Unifying Data Mixing and Selection via Geometric Exploration and Mining](https://arxiv.org/abs/2602.03772v1)
- [Reasoning with Latent Tokens in Diffusion Language Models](https://arxiv.org/abs/2602.03769v1)
- [Decision-oriented benchmarking to transform AI weather forecast access: Application to the Indian monsoon](https://arxiv.org/abs/2602.03767v1)
- [Conditional Flow Matching for Visually-Guided Acoustic Highlighting](https://arxiv.org/abs/2602.03762v1)
- [Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives](https://arxiv.org/abs/2602.03750v1)
- [Soft Sensor for Bottom-Hole Pressure Estimation in Petroleum Wells Using Long Short-Term Memory and Transfer Learning](https://arxiv.org/abs/2602.03737v1)
- [Fast-MWEM: Private Data Release in Sublinear Time](https://arxiv.org/abs/2602.03732v1)
- [CUBO: Self-Contained Retrieval-Augmented Generation on Consumer Laptops 10 GB Corpora, 16 GB RAM, Single-Device Deployment](https://arxiv.org/abs/2602.03731v1)
- [Efficient Variance-reduced Estimation from Generative EHR Models: The SCOPE and REACH Estimators](https://arxiv.org/abs/2602.03730v1)
- [Efficient Training of Boltzmann Generators Using Off-Policy Log-Dispersion Regularization](https://arxiv.org/abs/2602.03729v1)
- [Training Multi-Turn Search Agent via Contrastive Dynamic Branch Sampling](https://arxiv.org/abs/2602.03719v1)
- [VR-VFL: Joint Rate and Client Selection for Vehicular Federated Learning Under Imperfect CSI](https://arxiv.org/abs/2602.03711v1)
- [No Shortcuts to Culture: Indonesian Multi-hop Question Answering for Complex Cultural Understanding](https://arxiv.org/abs/2602.03709v1)
- [Beyond Tokens: Semantic-Aware Speculative Decoding for Efficient Inference by Probing Internal States](https://arxiv.org/abs/2602.03708v1)
- [OmniRAG-Agent: Agentic Omnimodal Reasoning for Low-Resource Long Audio-Video Question Answering](https://arxiv.org/abs/2602.03707v1)
- [Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models](https://arxiv.org/abs/2602.03704v1)
- [Anytime Pretraining: Horizon-Free Learning-Rate Schedules with Weight Averaging](https://arxiv.org/abs/2602.03702v1)
- [Data-Driven Graph Filters via Adaptive Spectral Shaping](https://arxiv.org/abs/2602.03698v1)
- [Conflict-Resolving and Sharpness-Aware Minimization for Generalized Knowledge Editing with Multiple Updates](https://arxiv.org/abs/2602.03696v1)
- [Agent Primitives: Reusable Latent Building Blocks for Multi-Agent Systems](https://arxiv.org/abs/2602.03695v1)
- [OCRTurk: A Comprehensive OCR Benchmark for Turkish](https://arxiv.org/abs/2602.03693v1)
- [LLM-Inspired Pretrain-Then-Finetune for Small-Data, Large-Scale Optimization](https://arxiv.org/abs/2602.03690v1)
- [Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation](https://arxiv.org/abs/2602.03689v1)
- [TodyComm: Task-Oriented Dynamic Communication for Multi-Round LLM-based Multi-Agent System](https://arxiv.org/abs/2602.03688v1)
- [QuAIL: Quality-Aware Inertial Learning for Robust Training under Data Corruption](https://arxiv.org/abs/2602.03686v1)
- [Universal One-third Time Scaling in Learning Peaked Distributions](https://arxiv.org/abs/2602.03685v1)
- [Improved Analysis of the Accelerated Noisy Power Method with Applications to Decentralized PCA](https://arxiv.org/abs/2602.03682v1)
- [Neural Attention Search Linear: Towards Adaptive Token-Level Hybrid Attention Models](https://arxiv.org/abs/2602.03681v1)
- [ContraLog: Log File Anomaly Detection with Contrastive Learning and Masked Language Modeling](https://arxiv.org/abs/2602.03678v1)
- [Instruction Anchors: Dissecting the Causal Dynamics of Modality Arbitration](https://arxiv.org/abs/2602.03677v1)
- [Equilibrium Propagation for Non-Conservative Systems](https://arxiv.org/abs/2602.03670v1)
- [Efficient Sequential Neural Network with Spatial-Temporal Attention and Linear LSTM for Robust Lane Detection Using Multi-Frame Images](https://arxiv.org/abs/2602.03669v1)
- [Mitigating Conversational Inertia in Multi-Turn Agents](https://arxiv.org/abs/2602.03664v1)
- [Sequential Group Composition: A Window into the Mechanics of Deep Learning](https://arxiv.org/abs/2602.03655v1)
- [RAGTurk: Best Practices for Retrieval Augmented Generation in Turkish](https://arxiv.org/abs/2602.03652v1)
- [Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration](https://arxiv.org/abs/2602.03647v1)
- [Reinforcement Fine-Tuning for History-Aware Dense Retriever in RAG](https://arxiv.org/abs/2602.03645v1)
- [CTTVAE: Latent Space Structuring for Conditional Tabular Data Generation on Imbalanced Datasets](https://arxiv.org/abs/2602.03641v1)
- [Tutorial on Reasoning for IR & IR for Reasoning](https://arxiv.org/abs/2602.03640v1)
- [TRE: Encouraging Exploration in the Trust Region](https://arxiv.org/abs/2602.03635v1)
- [BIRDTurk: Adaptation of the BIRD Text-to-SQL Dataset to Turkish](https://arxiv.org/abs/2602.03633v1)
- [Can LLMs Do Rocket Science? Exploring the Limits of Complex Reasoning with GTOC 12](https://arxiv.org/abs/2602.03630v1)
- [Ultra Fast PDE Solving via Physics Guided Few-step Diffusion](https://arxiv.org/abs/2602.03627v1)
- [Learning Query-Specific Rubrics from Human Preferences for DeepResearch Report Generation](https://arxiv.org/abs/2602.03619v1)
- [Quantization-Aware Regularizers for Deep Neural Networks Compression](https://arxiv.org/abs/2602.03614v1)
- [Simulation-Based Inference via Regression Projection and Batched Discrepancies](https://arxiv.org/abs/2602.03613v1)
- [Generator-based Graph Generation via Heat Diffusion](https://arxiv.org/abs/2602.03612v1)
- [Explanations Leak: Membership Inference with Differential Privacy and Active Learning Defense](https://arxiv.org/abs/2602.03611v1)
- [Controlling Output Rankings in Generative Engines for LLM-based Search](https://arxiv.org/abs/2602.03608v1)
- [A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.03604v1)
- [SAGE-5GC: Security-Aware Guidelines for Evaluating Anomaly Detection in the 5G Core Network](https://arxiv.org/abs/2602.03596v1)
- [Efficient Algorithms for Partial Constraint Satisfaction Problems over Control-flow Graphs](https://arxiv.org/abs/2602.03588v1)
- [CL-bench: A Benchmark for Context Learning](https://arxiv.org/abs/2602.03587v1)
- [APEX: Probing Neural Networks via Activation Perturbation](https://arxiv.org/abs/2602.03586v1)
- [$V_0$: A Generalist Value Model for Any Policy at State Zero](https://arxiv.org/abs/2602.03584v1)
- [Optimization and Generation in Aerodynamics Inverse Design](https://arxiv.org/abs/2602.03582v1)
- [Don't believe everything you read: Understanding and Measuring MCP Behavior under Misleading Tool Descriptions](https://arxiv.org/abs/2602.03580v1)
- [Use Graph When It Needs: Efficiently and Adaptively Integrating Retrieval-Augmented Generation with Graphs](https://arxiv.org/abs/2602.03578v1)
- [Asymmetric Hierarchical Anchoring for Audio-Visual Joint Representation: Resolving Information Allocation Ambiguity for Robust Cross-Modal Generalization](https://arxiv.org/abs/2602.03570v1)
- [EHRWorld: A Patient-Centric Medical World Model for Long-Horizon Clinical Trajectories](https://arxiv.org/abs/2602.03569v1)
- [EVE: Efficient Verification of Data Erasure through Customized Perturbation in Approximate Unlearning](https://arxiv.org/abs/2602.03567v1)
- [Riemannian Neural Optimal Transport](https://arxiv.org/abs/2602.03566v1)
- [CoGenCast: A Coupled Autoregressive-Flow Generative Framework for Time Series Forecasting](https://arxiv.org/abs/2602.03564v1)
- [ACL: Aligned Contrastive Learning Improves BERT and Multi-exit BERT Fine-tuning](https://arxiv.org/abs/2602.03563v1)
- [NPCNet: Navigator-Driven Pseudo Text for Deep Clustering of Early Sepsis Phenotyping](https://arxiv.org/abs/2602.03562v1)
- [HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing](https://arxiv.org/abs/2602.03560v1)
- [ELIQ: A Label-Free Framework for Quality Assessment of Evolving AI-Generated Images](https://arxiv.org/abs/2602.03558v1)
- [When Single Answer Is Not Enough: Rethinking Single-Step Retrosynthesis Benchmarks for LLMs](https://arxiv.org/abs/2602.03554v1)
- [Assessing the Impact of Typological Features on Multilingual Machine Translation in the Age of Large Language Models](https://arxiv.org/abs/2602.03551v1)
- [SEAD: Self-Evolving Agent for Multi-Turn Service Dialogue](https://arxiv.org/abs/2602.03548v1)
- [How to Train Your Resistive Network: Generalized Equilibrium Propagation and Analytical Learning](https://arxiv.org/abs/2602.03546v1)
- [Persona Generators: Generating Diverse Synthetic Personas at Scale](https://arxiv.org/abs/2602.03545v1)
- [Can Large Language Models Generalize Procedures Across Representations?](https://arxiv.org/abs/2602.03542v1)
- [Group Selection as a Safeguard Against AI Substitution](https://arxiv.org/abs/2602.03541v1)
- [MatGPTQ: Accurate and Efficient Post-Training Matryoshka Quantization](https://arxiv.org/abs/2602.03537v1)
- [Sparse Training of Neural Networks based on Multilevel Mirror Descent](https://arxiv.org/abs/2602.03535v1)
- [Robust Representation Learning in Masked Autoencoders](https://arxiv.org/abs/2602.03531v1)
- [Morphe: High-Fidelity Generative Video Streaming with Vision Foundation Model](https://arxiv.org/abs/2602.03529v1)
- [WARP Logic Neural Networks](https://arxiv.org/abs/2602.03527v1)
- [D3PIA: A Discrete Denoising Diffusion Model for Piano Accompaniment Generation From Lead sheet](https://arxiv.org/abs/2602.03523v1)
- [Live or Lie: Action-Aware Capsule Multiple Instance Learning for Risk Assessment in Live Streaming Platforms](https://arxiv.org/abs/2602.03520v1)
- [Rank-Learner: Orthogonal Ranking of Treatment Effects](https://arxiv.org/abs/2602.03517v1)
- [Not All Negative Samples Are Equal: LLMs Learn Better from Plausible Reasoning](https://arxiv.org/abs/2602.03516v1)
- [Mitigating Staleness in Asynchronous Pipeline Parallelism via Basis Rotation](https://arxiv.org/abs/2602.03515v1)
- [A Function-Space Stability Boundary for Generalization in Interpolating Learning Systems](https://arxiv.org/abs/2602.03514v1)
- [CMR: Contractive Mapping Embeddings for Robust Humanoid Locomotion on Unstructured Terrains](https://arxiv.org/abs/2602.03511v1)
- [Learning to Reason Faithfully through Step-Level Faithfulness Maximization](https://arxiv.org/abs/2602.03507v1)
- [Explaining the Explainer: Understanding the Inner Workings of Transformer-based Symbolic Regression Models](https://arxiv.org/abs/2602.03506v1)
- [Generative Decompression: Optimal Lossy Decoding Against Distribution Mismatch](https://arxiv.org/abs/2602.03505v1)
- [Reparameterization Flow Policy Optimization](https://arxiv.org/abs/2602.03501v1)
- [Lookahead Path Likelihood Optimization for Diffusion LLMs](https://arxiv.org/abs/2602.03496v1)
- [DALI: A Workload-Aware Offloading Framework for Efficient MoE Inference on Local PCs](https://arxiv.org/abs/2602.03495v1)
- [Least but not Last: Fine-tuning Intermediate Principal Components for Better Performance-Forgetting Trade-Offs](https://arxiv.org/abs/2602.03493v1)
- [Decoupling Skeleton and Flesh: Efficient Multimodal Table Reasoning with Disentangled Alignment and Structure-aware Guidance](https://arxiv.org/abs/2602.03491v1)
- [A Minimal Task Reveals Emergent Path Integration and Object-Location Binding in a Predictive Sequence Model](https://arxiv.org/abs/2602.03490v1)
- [DeepDFA: Injecting Temporal Logic in Deep Learning for Sequential Subsymbolic Applications](https://arxiv.org/abs/2602.03486v1)
- [Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning](https://arxiv.org/abs/2602.03485v1)
- [Preferences for Idiomatic Language are Acquired Slowly -- and Forgotten Quickly: A Case Study on Swedish](https://arxiv.org/abs/2602.03484v1)
- [When Routing Collapses: On the Degenerate Convergence of LLM Routers](https://arxiv.org/abs/2602.03478v1)
- [ScDiVa: Masked Discrete Diffusion for Joint Modeling of Single-Cell Identity and Expression](https://arxiv.org/abs/2602.03477v1)
- [Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts](https://arxiv.org/abs/2602.03473v1)
- [IntentRL: Training Proactive User-intent Agents for Open-ended Deep Research via Reinforcement Learning](https://arxiv.org/abs/2602.03468v1)
- [The Dual Role of Abstracting over the Irrelevant in Symbolic Explanations: Cognitive Effort vs. Understanding](https://arxiv.org/abs/2602.03467v1)
- [Quantum Circuit Generation via test-time learning with large language models](https://arxiv.org/abs/2602.03466v1)
- [Soft-Radial Projection for Constrained End-to-End Learning](https://arxiv.org/abs/2602.03461v1)
- [Causal Inference on Networks under Misspecified Exposure Mappings: A Partial Identification Framework](https://arxiv.org/abs/2602.03459v1)
- [Beyond Variance: Prompt-Efficient RLVR via Rare-Event Amplification and Bidirectional Pairing](https://arxiv.org/abs/2602.03452v1)
- [Score-based diffusion models for diffuse optical tomography with uncertainty quantification](https://arxiv.org/abs/2602.03449v1)
- [Hierarchical Concept-to-Appearance Guidance for Multi-Subject Image Generation](https://arxiv.org/abs/2602.03448v1)
- [CRL-VLA: Continual Vision-Language-Action Learning](https://arxiv.org/abs/2602.03445v1)
- [A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces](https://arxiv.org/abs/2602.03442v1)
- [Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents](https://arxiv.org/abs/2602.03439v1)
- [DiscoverLLM: From Executing Intents to Discovering Them](https://arxiv.org/abs/2602.03429v1)
- [CoCoEmo: Composable and Controllable Human-Like Emotional TTS via Activation Steering](https://arxiv.org/abs/2602.03420v1)
- [SWE-World: Building Software Engineering Agents in Docker-Free Environments](https://arxiv.org/abs/2602.03419v1)
- [FactNet: A Billion-Scale Knowledge Graph for Multilingual Factual Grounding](https://arxiv.org/abs/2602.03417v1)
- [Most Convolutional Networks Suffer from Small Adversarial Perturbations](https://arxiv.org/abs/2602.03415v1)
- [Socratic-Geo: Synthetic Data Generation and Geometric Reasoning via Multi-Agent Interaction](https://arxiv.org/abs/2602.03414v1)
- [Verified Critical Step Optimization for LLM Agents](https://arxiv.org/abs/2602.03412v1)
- [SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training](https://arxiv.org/abs/2602.03411v1)
- [Enhancing Quantum Diffusion Models for Complex Image Generation](https://arxiv.org/abs/2602.03405v1)
- [Feasible strategies for conflict resolution within intuitionistic fuzzy preference-based conflict situations](https://arxiv.org/abs/2602.03403v1)
- [Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility](https://arxiv.org/abs/2602.03402v1)
- [Precision in Practice: Knowledge Guided Code Summarizing Grounded in Industrial Expectations](https://arxiv.org/abs/2602.03400v1)
- [Towards Distillation-Resistant Large Language Models: An Information-Theoretic Perspective](https://arxiv.org/abs/2602.03396v1)
- [The Label Horizon Paradox: Rethinking Supervision Targets in Financial Forecasting](https://arxiv.org/abs/2602.03395v1)
- [Improving the Linearized Laplace Approximation via Quadratic Approximations](https://arxiv.org/abs/2602.03394v1)
- [On the Entropy Dynamics in Reinforcement Fine-Tuning of Large Language Models](https://arxiv.org/abs/2602.03392v1)
- [From Vicious to Virtuous Cycles: Synergistic Representation Learning for Unsupervised Video Object-Centric Learning](https://arxiv.org/abs/2602.03390v1)
- [Chain-of-Goals Hierarchical Policy for Long-Horizon Offline Goal-Conditioned RL](https://arxiv.org/abs/2602.03389v1)
- [Toward a Sustainable Federated Learning Ecosystem: A Practical Least Core Mechanism for Payoff Allocation](https://arxiv.org/abs/2602.03387v1)
- [An Approximate Ascent Approach To Prove Convergence of PPO](https://arxiv.org/abs/2602.03386v1)
- [Dynamic Topology Optimization for Non-IID Data in Decentralized Learning](https://arxiv.org/abs/2602.03383v1)
- [Rethinking Benign Relearning: Syntax as the Hidden Driver of Unlearning Failures](https://arxiv.org/abs/2602.03379v1)
- [SLIM-Diff: Shared Latent Image-Mask Diffusion with Lp loss for Data-Scarce Epilepsy FLAIR MRI](https://arxiv.org/abs/2602.03372v1)
- [Symbol-Aware Reasoning with Masked Discrete Diffusion for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2602.03370v1)
- [Pursuing Best Industrial Practices for Retrieval-Augmented Generation in the Medical Domain](https://arxiv.org/abs/2602.03368v1)
- [MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling](https://arxiv.org/abs/2602.03359v1)
- [GFlowPO: Generative Flow Network as a Language Model Prompt Optimizer](https://arxiv.org/abs/2602.03358v1)
- [Achieving Linear Speedup for Composite Federated Learning](https://arxiv.org/abs/2602.03357v1)
- [PACE: Pretrained Audio Continual Learning](https://arxiv.org/abs/2602.03355v1)
- [Causal Graph Learning via Distributional Invariance of Cause-Effect Relationship](https://arxiv.org/abs/2602.03353v1)
- [PEGRL: Improving Machine Translation by Post-Editing Guided Reinforcement Learning](https://arxiv.org/abs/2602.03352v1)
- [Building Interpretable Models for Moral Decision-Making](https://arxiv.org/abs/2602.03351v1)
- [Robustness as an Emergent Property of Task Performance](https://arxiv.org/abs/2602.03344v1)
- [Tiled Prompts: Overcoming Prompt Underspecification in Image and Video Super-Resolution](https://arxiv.org/abs/2602.03342v1)
- [MentalSeek-Dx: Towards Progressive Hypothetico-Deductive Reasoning for Real-world Psychiatric Diagnosis](https://arxiv.org/abs/2602.03340v1)
- [Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention](https://arxiv.org/abs/2602.03338v1)
- [Bayesian Conformal Prediction as a Decision Risk Problem](https://arxiv.org/abs/2602.03331v1)
- [From Inexact Gradients to Byzantine Robustness: Acceleration and Optimization under Similarity](https://arxiv.org/abs/2602.03329v1)
- [A Novel approach to portfolio construction](https://arxiv.org/abs/2602.03325v1)
- [MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning](https://arxiv.org/abs/2602.03320v1)
- [MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research](https://arxiv.org/abs/2602.03318v1)
- [Multiparameter Uncertainty Mapping in Quantitative Molecular MRI using a Physics-Structured Variational Autoencoder (PS-VAE)](https://arxiv.org/abs/2602.03317v1)
- [Memora: A Harmonic Memory Representation Balancing Abstraction and Specificity](https://arxiv.org/abs/2602.03315v1)
- [RDT2: Exploring the Scaling Limit of UMI Data Towards Zero-Shot Cross-Embodiment Generalization](https://arxiv.org/abs/2602.03310v1)
- [Entropy-Gated Selective Policy Optimization:Token-Level Gradient Allocation for Hybrid Training of Large Language Models](https://arxiv.org/abs/2602.03309v1)
- [Learning to Select: Query-Aware Adaptive Dimension Selection for Dense Retrieval](https://arxiv.org/abs/2602.03306v1)
- [medR: Reward Engineering for Clinical Offline Reinforcement Learning via Tri-Drive Potential Functions](https://arxiv.org/abs/2602.03305v1)
- [Full end-to-end diagnostic workflow automation of 3D OCT via foundation model-driven AI for retinal diseases](https://arxiv.org/abs/2602.03302v1)
- [Periodic Regularized Q-Learning](https://arxiv.org/abs/2602.03301v1)
- [R1-SyntheticVL: Is Synthetic Data from Generative Models Ready for Multimodal Large Language Model?](https://arxiv.org/abs/2602.03300v1)
- [Lipschitz Multiscale Deep Equilibrium Models: A Theoretically Guaranteed and Accelerated Approach](https://arxiv.org/abs/2602.03297v1)
- [POP: Prefill-Only Pruning for Efficient Large Model Inference](https://arxiv.org/abs/2602.03295v1)

_…and 10 more._

</details>

<details><summary>Search definitions</summary>

- Materials & Physics (cond-mat / comp-ph / chem-ph) — `cat:cond-mat.mtrl-sci OR cat:physics.comp-ph OR cat:physics.chem-ph`
- AI/ML (cs.AI/cs.LG/stat.ML/cs.CL) — `cat:cs.AI OR cat:cs.LG OR cat:stat.ML OR cat:cs.CL`

</details>
